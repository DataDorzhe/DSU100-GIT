{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8a828c6-b34b-468d-8775-fb3670118097",
   "metadata": {
    "id": "e0ebef84-7c99-40c8-b1db-44afe54ea513"
   },
   "source": [
    "# Домашнее задание по теме «Механизм внимания»"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d513b223-5b53-453f-8d7e-1075c087058c",
   "metadata": {},
   "source": [
    "1. Возьмите англо-русскую пару фраз (https://www.manythings.org/anki/)\n",
    "2. Обучите на них seq2seq with attention\n",
    "    1. На основе скалярного произведения\n",
    "    2. На основе MLP\n",
    "3. Оцените качествотво"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721a8242-b3e8-4117-8bca-5fc7391f7bbc",
   "metadata": {
    "id": "ef2d935c-e4c6-46b9-bff0-8771b9d5ec95"
   },
   "source": [
    "# Загрузка библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "edb7eed8-5501-4f78-91ba-95f212e6b318",
   "metadata": {
    "id": "5687a1ec-c8d8-4cde-b87c-866621ec70d5"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6a9a7ca-8026-46a4-907b-9be6a8d86cc4",
   "metadata": {
    "id": "acfd831f-57e4-4d89-bdb4-8938dcbfcb58"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2003aa38-8cfb-4c60-9632-06f3ebd30fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "import os\n",
    "from io import open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f63a2cf4-291f-4abc-8c31-9a7374d90f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b7b35f6-011b-47b1-a48c-df27b537405e",
   "metadata": {
    "id": "93150af3-d550-46af-96a4-709507c17d8b"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "214b4abb-5f5f-4084-bdbf-70a0be836b1d",
   "metadata": {
    "id": "c41f774c-13f5-495c-b49a-0830e2e6202f"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "da01cfde-1b58-47cc-85cf-33666af21f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb683da5-4cbb-4e7e-b45b-f6321310d611",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d36bd0-a18c-4e96-9f6d-731d80322ed0",
   "metadata": {
    "id": "1438447f-21dc-48e1-909f-c64f95024466"
   },
   "source": [
    "# Параметры GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b12c1196-f9fb-412f-a716-222d7676fa7f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c248bc02-6322-4945-9528-b591ea42457a",
    "outputId": "55633407-4a96-43d7-917f-9610150f09d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA поддерживается системой?\n",
      "CUDA-версия: 11.8\n",
      "ID текущего CUDA устройства:0\n",
      "Имя текущего CUDA устройства:NVIDIA GeForce RTX 2060\n"
     ]
    }
   ],
   "source": [
    "print(f\"CUDA поддерживается системой?\")\n",
    "if torch.cuda.is_available() == True:\n",
    "    print(f\"CUDA-версия: {torch.version.cuda}\")\n",
    "    cuda_id = torch.cuda.current_device()\n",
    "    print(f\"ID текущего CUDA устройства:{torch.cuda.current_device()}\")\n",
    "    print(f\"Имя текущего CUDA устройства:{torch.cuda.get_device_name(cuda_id)}\")\n",
    "else:\n",
    "    print(f\"Нет\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05662382-87c6-4b7b-940d-179f201d765b",
   "metadata": {
    "id": "926f501b-2aa8-402d-b102-10a55b119dba"
   },
   "source": [
    "# Выбор процессора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4c29f5a8-c5f0-4d65-892f-3a1ec0e84289",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "1510b80a-79ca-4f09-a0d3-7e5ce1d99d67",
    "outputId": "c5b98f32-5890-4547-971e-744e35af4ad8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9f8521-9ca2-4f78-b867-e4a6a89ea472",
   "metadata": {},
   "source": [
    "# Импорт данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8b04f244-8fac-4720-b21e-c78983e5b3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = codecs.open( \"rus.txt\", \"r\", \"utf-8\" )\n",
    "data = file.read()\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8a992f01-5294-4bbe-8352-fe4d75445c2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ng.\tПоскольку сайтов, посвящённых какой-либо теме, как правило, несколько, я обычно просто нажимаю на кнопку \"назад\", если попадаю на страницу со всплывающей рекламой. Я просто перехожу на следующую страницу, найденную гуглом, и надеюсь найти что-то менее раздражающее.\tCC-BY 2.0 (France) Attribution: tatoeba.org #954270 (CK) & #6383010 (odexed)\n",
      "If someone who doesn't know your background says that you sound like a native speaker, it means they probably noticed something about your speaking that made them realize you weren't a native speaker. In other words, you don't really sound like a native speaker.\tЕсли кто-то незнакомый говорит, что вы говорите как носитель языка, это значит, что он, вероятно, заметил что-то в вашей речи, что дало ему понять, что вы не носитель. Другими словами, вы не говорите как носитель.\tCC-BY 2.0 (France) Attribution: tatoeba.org #953936 (CK) & #10644468 (notenoughsun)\n",
      "Doubtless there exists in this world precisely the right woman for any given man to marry and vice versa; but when you consider that a human being has the opportunity of being acquainted with only a few hundred people, and out of the few hundred that there are but a dozen or less whom he knows intimately, and out of the dozen, one or two friends at most, it will easily be seen, when we remember the number of millions who inhabit this world, that probably, since the earth was created, the right man has never yet met the right woman.\tНесомненно, для каждого мужчины в этом мире где-то есть подходящая женщина, которая может стать ему женой, обратное верно и для женщин. Но если учесть, что у человека может быть максимум несколько сотен знакомых, из которых лишь дюжина, а то и меньше, тех, кого он знает близко, а из этой дюжины у него один или от силы два друга, то можно легко увидеть, что с учётом миллионов живущих на Земле людей, ни один подходящий мужчина, возможно, ещё не встретил подходящую женщину.\tCC-BY 2.0 (France) Attribution: tatoeba.org #7697649 (RM) & #7730831 (odexed)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(data[-2000:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e984d51-57e1-4957-ba59-974142f771e3",
   "metadata": {},
   "source": [
    "# Входные параметры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "60647603-d9eb-4e6f-9d7d-c7bb8650c627",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "random.seed(SEED)\n",
    "MAX_LENGTH = 10\n",
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "lang1 = 'rus'\n",
    "lang2 = 'eng'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "080f330c-7252-45b2-84c5-d0066fe92a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "if device=='cuda':\n",
    "  torch.cuda.manual_seed(SEED)\n",
    "  torch.backends.cudnn.deterministic = True\n",
    "else:\n",
    "  torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "83b4f804-ac16-47c4-bec8-4441275372c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_prefixes = (\n",
    "    \"i am \", \"i m \",\n",
    "    \"he is\", \"he s \",\n",
    "    \"she is\", \"she s\",\n",
    "    \"you are\", \"you re \",\n",
    "    \"we are\", \"we re \",\n",
    "    \"they are\", \"they re \"\n",
    ")\n",
    "\n",
    "rnn_types = [nn.LSTM, nn.GRU]\n",
    "\n",
    "attn_types = ['scalar', 'mlp']\n",
    "cols = ['RNN_Type', 'attn_types', 'loss', 'perplexity', 'learning_time']\n",
    "PATH = os.path.abspath(\"rus.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200114ac-2d90-45ad-a1ce-54643b0c5ca9",
   "metadata": {},
   "source": [
    "# Функции"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb6a2ee-a9cb-4dad-95d1-a0af61bb93b4",
   "metadata": {},
   "source": [
    "## Фасовка слов по словарям"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ac9c538b-e365-4170-bb53-7158d3d02921",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2  # Count SOS and EOS\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b57ae31-502c-43a0-8e14-c5ab81fd4911",
   "metadata": {},
   "source": [
    "## Кодировка в ASCII"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "459f6141-d2d4-43bc-a3af-5e92c8cfbeea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c1ade5-ecf8-489c-941d-d74e108f612a",
   "metadata": {},
   "source": [
    "## Нормализация строк"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a72e0755-44fb-4af5-ab38-cc445939c77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Zа-яА-ЯёЁ.!?]+\", r\" \", s)\n",
    "    # s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9263b390-503a-43a2-99fc-5d813ab9ab40",
   "metadata": {},
   "source": [
    "## Чтение файла"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1118b120-139b-4cab-b03d-99ac6eb0f9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readLangs(lang1, lang2, reverse=False):\n",
    "    print(\"Reading lines...\")\n",
    "\n",
    "    # Read the file and split into lines\n",
    "    lines = open('rus.txt', encoding='utf-8').\\\n",
    "        read().strip().split('\\n')\n",
    "\n",
    "    # Split every line into pairs and normalize\n",
    "    pairs = [[normalizeString(s) for s in l.split('\\t')][:2] for l in lines] #\n",
    "\n",
    "    # Reverse pairs, make Lang instances\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang(lang2)\n",
    "        output_lang = Lang(lang1)\n",
    "    else:\n",
    "        input_lang = Lang(lang1)\n",
    "        output_lang = Lang(lang2)\n",
    "\n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c426b77-0eb2-4391-87ec-dfa59384c24f",
   "metadata": {},
   "source": [
    "## Токенизация слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f887edf9-0e31-4fc6-ada6-27df6e8aa580",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterPair(p, prefixes):\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
    "        len(p[1].split(' ')) < MAX_LENGTH and \\\n",
    "        p[1].startswith(prefixes)\n",
    "\n",
    "def filterPairs(pairs, prefixes):\n",
    "    return [pair for pair in pairs if filterPair(pair, prefixes)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ada6081-1138-423a-bb6d-2abe686f8c02",
   "metadata": {},
   "source": [
    "## Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1f1f1ee3-8fa1-4957-afc1-12d4c5fbddb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareData(lang1, lang2, prefixes, reverse=False):\n",
    "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    pairs = filterPairs(pairs, prefixes)\n",
    "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07cab7b-3d21-4d1e-bd43-7f9ddc88efa2",
   "metadata": {},
   "source": [
    "## Кодировщик"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b294e292-79a8-4cb5-bcd7-d4c9ea5ede05",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, rnn_type):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.rnn = rnn_type(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        output, hidden = self.rnn(output, hidden)\n",
    "        return output, hidden\n",
    "        \n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c89400c-6f07-4f86-8e58-0449e61da8b9",
   "metadata": {},
   "source": [
    "## Декодеровщик на основе скалярного произведения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "18d29183-868e-443c-a8ce-c29074df3f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttnDecoderRNN1(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, rnn_type, dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "        super(AttnDecoderRNN1, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.rnn = rnn_type(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "\n",
    "        attn_weights = F.softmax((embedded[0] @ encoder_outputs.T)/self.max_length**0.5, dim=1)\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "                                 encoder_outputs.unsqueeze(0))\n",
    "\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.rnn(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ed8389-fc5d-4dd4-b0b0-5f8c8127bc4a",
   "metadata": {},
   "source": [
    "## Декодировщик на основе MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0f704a3a-ade5-4714-a046-9edd3eb98464",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttnDecoderRNN2(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, rnn_type, dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "        super(AttnDecoderRNN2, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.rnn = rnn_type(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "        self.rnn_type_name = rnn_type.__name__\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "\n",
    "        if  self.rnn_type_name == 'LSTM':\n",
    "            attn_weights = F.softmax(self.attn(torch.cat((embedded[0], hidden[0][0]), 1)), dim=1)\n",
    "        else:\n",
    "             attn_weights = F.softmax(self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "                                 encoder_outputs.unsqueeze(0))\n",
    "\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        output = F.tanh(output)\n",
    "        output, hidden = self.rnn(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ceb9768-6c4a-4d33-a2cb-5d5f9cfa5a72",
   "metadata": {},
   "source": [
    "## Формирование тензора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e3dcc574-b622-4a33-86f7-3886a45f1fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "def tensorsFromPair(pair, input_lang, output_lang):\n",
    "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
    "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
    "    return (input_tensor, target_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4e65a5-db61-4633-bdf0-4702241370f2",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "00ad3be1-7505-422c-b99d-375dd16240f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(input_tensor, target_tensor,\n",
    "          encoder, decoder, encoder_optimizer, decoder_optimizer,\n",
    "          criterion, max_length, rnn_type, teacher_forcing_ratio):\n",
    "\n",
    "    if rnn_type.__name__ == 'LSTM':\n",
    "        encoder_hidden = (encoder.initHidden(), encoder.initHidden())\n",
    "    else:\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "    loss = 0\n",
    "    total_words = 0\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_tensor[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            decoder_input = target_tensor[di]  # Teacher forcing\n",
    "            total_words += target_tensor[di].numel()\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            total_words += target_tensor[di].numel()\n",
    "            if decoder_input.item() == EOS_token:\n",
    "                break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "    avg_loss = loss / total_words\n",
    "    perplexity = torch.exp(avg_loss)\n",
    "    return loss.item() / target_length, perplexity.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf94fbc-6cb7-45f2-819b-d51e3dc9e5e8",
   "metadata": {},
   "source": [
    "## Для расчёта длительности обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "171c858b-f450-435a-81ec-1fe260dc0b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4437b83e-0c33-4233-875f-fca738bc5806",
   "metadata": {},
   "source": [
    "## Итеративное обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "46206762-9fd6-492e-b641-87fba638f787",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainIters(pair_sentenses, encoder, decoder, learning_rate, n_iters,\n",
    "               max_length, rnn_type, teacher_forcing_ratio, input_lan, output_lan,\n",
    "               print_every=5000, plot_every=500):\n",
    "\n",
    "    start = time.time()\n",
    "    print_loss_total = 0\n",
    "    print_loss_avg = 0\n",
    "    print_perplexity = 0\n",
    "\n",
    "    encoder_optimizer = optim.Adam(encoder.parameters())\n",
    "    decoder_optimizer = optim.Adam(decoder.parameters())\n",
    "\n",
    "    training_pairs = [tensorsFromPair(random.choice(pair_sentenses),\n",
    "                                      input_lan, output_lan)\n",
    "                                      for i in range(n_iters)]\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for iter in tqdm(range(1, n_iters + 1)):\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "\n",
    "        loss, perplexity = train(input_tensor, target_tensor, encoder, decoder,\n",
    "                     encoder_optimizer, decoder_optimizer, criterion,\n",
    "                     max_length, rnn_type, teacher_forcing_ratio)\n",
    "\n",
    "        print_loss_total += loss\n",
    "        print_perplexity += perplexity\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_perplexity_avg = print_perplexity / print_every\n",
    "            print_loss_total = 0\n",
    "            print_perplexity = 0\n",
    "\n",
    "            print('%s (%d %d%%) %.4f %.4f'  % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg, print_perplexity_avg ))\n",
    "    return print_loss_avg, print_perplexity_avg, timeSince(start, iter / n_iters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1de9e7d-7df8-4c27-9dcd-f4f04b7ea82f",
   "metadata": {},
   "source": [
    "## Механизм внимания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "585649d5-9da2-4af8-9b66-172092e1c024",
   "metadata": {},
   "outputs": [],
   "source": [
    "def showAttention(input_sentence, output_words, attentions):\n",
    "    # Set up figure with colorbar\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    cax = ax.matshow(attentions.numpy(), cmap='bone')\n",
    "    fig.colorbar(cax)\n",
    "\n",
    "    # Set up axes\n",
    "    ax.set_xticklabels([''] + input_sentence.split(' ') +\n",
    "                       ['<EOS>'], rotation=90)\n",
    "    ax.set_yticklabels([''] + output_words)\n",
    "\n",
    "    # Show label at every tick\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "56f62a7e-318b-4eb5-ad53-1f14aeb9aa79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateAndShowAttention(encoder2, decoder2, max_length, input_sentence):\n",
    "    output_words, attentions = evaluate(\n",
    "        encoder2, decoder2, input_sentence, max_length,\n",
    "             rnn_type, input_lang, output_lang)\n",
    "    print('input =', input_sentence)\n",
    "    print('output =', ' '.join(output_words))\n",
    "    showAttention(input_sentence, output_words, attentions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5cf1d36-9710-4bc5-9207-8376748aefdb",
   "metadata": {},
   "source": [
    "## Оценка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a49eac62-d146-48ab-8647-f249bd71199a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, max_length,\n",
    "             rnn_type, inp_lang, out_lang):\n",
    "\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(inp_lang, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "\n",
    "        if rnn_type.__name__ == 'LSTM':\n",
    "            encoder_hidden = (encoder.initHidden(), encoder.initHidden())\n",
    "        else:\n",
    "            encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
    "                                                     encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        decoded_words = []\n",
    "        decoder_attentions = torch.zeros(max_length, max_length)\n",
    "\n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            decoder_attentions[di] = decoder_attention.data\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            if topi.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(out_lang.index2word[topi.item()])\n",
    "\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "        return decoded_words, decoder_attentions[:di + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "be825402-50f5-4baa-9919-2dfc8401660b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateRandomly(pair_sen, encoder, decoder, max_length,\n",
    "                     rnn_, in_lang, o_lang,  n=10):\n",
    "\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pair_sen)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words, _ = evaluate(encoder, decoder, pair[0], MAX_LENGTH,\n",
    "                                rnn_, in_lang, o_lang)\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce947a06-d12c-4b74-95c3-b23b70183548",
   "metadata": {},
   "source": [
    "## Функция для тестирования модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6eb0a19d-8689-403e-aa11-daef8fe4c5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(max_length, hidden_size = 256,\n",
    "               learn_rate = 0.006, prefixes=eng_prefixes, reverse=False,\n",
    "               teach_force_ratio = 0.5, attn_type = 'scalar',\n",
    "               num_iters = 500, every = 100):\n",
    "\n",
    "        encoder2 = EncoderRNN(input_lang.n_words, hidden_size, rnn_type\n",
    "                               ).to(device)\n",
    "        if attn_type == 'scalar':\n",
    "          decoder2 = AttnDecoderRNN1(hidden_size, output_lang.n_words, rnn_type\n",
    "                                ).to(device)\n",
    "        elif attn_type == 'mlp':\n",
    "          decoder2 = AttnDecoderRNN2(hidden_size, output_lang.n_words, rnn_type\n",
    "                                ).to(device)\n",
    "        print(f'{rnn_type.__name__}, {attn_type} \\n\\ntraining')\n",
    "        print('===========================')\n",
    "        loss_, perplexity, learning_time = trainIters(pair_s, encoder2, decoder2, learn_rate, num_iters,\n",
    "                          max_length, rnn_type, teach_force_ratio,\n",
    "                          input_lang, output_lang, every)\n",
    "\n",
    "        print('\\nevaluation\\n')\n",
    "        evaluateRandomly(pair_s, encoder2, decoder2, max_length,\n",
    "                         rnn_type, input_lang, output_lang)\n",
    "        print('----------------------------------------------------------------------')\n",
    "        string          = [rnn_type.__name__, attn_type, loss_, perplexity,  learning_time]\n",
    "        df.loc[len(df)] = string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e378776-afe9-4050-ba84-f8a6b075c5e6",
   "metadata": {},
   "source": [
    "# Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9124d3c2-e88c-4525-8756-1221e00939fc",
   "metadata": {},
   "source": [
    "## Подготовительное"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "41d5b003-dc31-40fa-9041-719c6498926b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 496059 sentence pairs\n",
      "Trimmed to 28719 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "eng 10177\n",
      "rus 4303\n",
      "['я младше его на два года .', 'i m two years younger than he is .']\n"
     ]
    }
   ],
   "source": [
    "input_lang, output_lang, pair_s = prepareData(lang1, lang2, prefixes=eng_prefixes, reverse=True)\n",
    "print(random.choice(pair_s))\n",
    "df = pd.DataFrame(columns=cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb0c75a-e3d4-4423-a8be-e489d285941e",
   "metadata": {},
   "source": [
    "## seq2seq с механизмом внимания scalar (GRU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "dd35885b-5bf1-403c-9c02-eaab50b0c560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRU, scalar \n",
      "\n",
      "training\n",
      "===========================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93e548a294c442569ee96a68c038c1dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 44s (- 6m 42s) (2000 10%) 3.1170 89.8668\n",
      "1m 26s (- 5m 46s) (4000 20%) 2.7386 40.8410\n",
      "2m 9s (- 5m 1s) (6000 30%) 2.4986 33.0894\n",
      "2m 51s (- 4m 17s) (8000 40%) 2.3710 33.2025\n",
      "3m 37s (- 3m 37s) (10000 50%) 2.2277 34.8826\n",
      "4m 24s (- 2m 56s) (12000 60%) 2.1245 25.7380\n",
      "5m 11s (- 2m 13s) (14000 70%) 2.0436 30.6652\n",
      "6m 2s (- 1m 30s) (16000 80%) 1.9833 23.5864\n",
      "6m 57s (- 0m 46s) (18000 90%) 1.8757 26.2345\n",
      "7m 53s (- 0m 0s) (20000 100%) 1.8718 26.6177\n",
      "\n",
      "evaluation\n",
      "\n",
      "> мы закрыты до дальнеишего уведомления .\n",
      "= we are closed until further notice .\n",
      "< we are never satisfied . <EOS>\n",
      "\n",
      "> у него неприятности .\n",
      "= he is in trouble .\n",
      "< he is in trouble . <EOS>\n",
      "\n",
      "> я в хорошеи форме .\n",
      "= i m in good shape .\n",
      "< i m in good . <EOS>\n",
      "\n",
      "> я к этому не готова .\n",
      "= i m not ready for this .\n",
      "< i m not ready to that . <EOS>\n",
      "\n",
      "> боюсь что вы не можете поити туда .\n",
      "= i m afraid you can t go there .\n",
      "< i m afraid you can t there you . <EOS>\n",
      "\n",
      "> вы наивны .\n",
      "= you re naive .\n",
      "< you re so . <EOS>\n",
      "\n",
      "> я намного больше чем ты .\n",
      "= i m a lot bigger than you are .\n",
      "< i m much than you think . <EOS>\n",
      "\n",
      "> я не суеверен .\n",
      "= i m not superstitious .\n",
      "< i m not a . <EOS>\n",
      "\n",
      "> везет вам .\n",
      "= you re lucky .\n",
      "< you re lucky . <EOS>\n",
      "\n",
      "> я вообще не жалею .\n",
      "= i m glad i did it .\n",
      "< i m not one who . <EOS>\n",
      "\n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "rnn_type = nn.GRU\n",
    "test_model(max_length = MAX_LENGTH,\n",
    "           learn_rate = 0.0001, prefixes=eng_prefixes, reverse=True, teach_force_ratio = 0.5,\n",
    "           attn_type = 'scalar', num_iters = 20000, every = 2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb1b399-7e42-46e7-bf11-f99e6ea369b2",
   "metadata": {},
   "source": [
    "## seq2seq с механизмом внимания scalar (LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a2a931da-fb84-4324-8151-b2dea6e1c09b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM, scalar \n",
      "\n",
      "training\n",
      "===========================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "798f0246ccfa4f95aeeee930ecf79173",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 58s (- 8m 47s) (2000 10%) 3.1291 87.7061\n",
      "1m 55s (- 7m 40s) (4000 20%) 2.7966 34.2899\n",
      "2m 52s (- 6m 42s) (6000 30%) 2.6726 30.6411\n",
      "3m 50s (- 5m 45s) (8000 40%) 2.5410 30.2487\n",
      "4m 47s (- 4m 47s) (10000 50%) 2.4614 27.2598\n",
      "5m 43s (- 3m 49s) (12000 60%) 2.3552 27.3516\n",
      "6m 39s (- 2m 51s) (14000 70%) 2.2960 28.7493\n",
      "7m 36s (- 1m 54s) (16000 80%) 2.2638 29.4868\n",
      "8m 32s (- 0m 56s) (18000 90%) 2.1730 28.5271\n",
      "9m 28s (- 0m 0s) (20000 100%) 2.1500 23.3005\n",
      "\n",
      "evaluation\n",
      "\n",
      "> я здесь не в отпуске .\n",
      "= i m not here for a vacation .\n",
      "< i m not in here here . <EOS>\n",
      "\n",
      "> я не настолько глупа !\n",
      "= i m not that stupid .\n",
      "< i m not that . . <EOS>\n",
      "\n",
      "> ты мне чего то недоговариваешь .\n",
      "= you re not telling me something .\n",
      "< you re going to need me . <EOS>\n",
      "\n",
      "> я помогу тому .\n",
      "= i m going to help tom .\n",
      "< i m going to . . <EOS>\n",
      "\n",
      "> ты командуешь .\n",
      "= you re in command .\n",
      "< you re a . <EOS>\n",
      "\n",
      "> мы большие счастливчики .\n",
      "= we re very fortunate .\n",
      "< we re both in . <EOS>\n",
      "\n",
      "> я привык к здешнему климату .\n",
      "= i m accustomed to the climate here .\n",
      "< i m used to used to . . <EOS>\n",
      "\n",
      "> я не из тех кто опускает руки .\n",
      "= i m no quitter .\n",
      "< i m not worried about the . <EOS>\n",
      "\n",
      "> они иностранки .\n",
      "= they re foreigners .\n",
      "< they re all . <EOS>\n",
      "\n",
      "> я очень устала .\n",
      "= i m so tired .\n",
      "< i m very tired . <EOS>\n",
      "\n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "rnn_type = nn.LSTM\n",
    "test_model(max_length = MAX_LENGTH,\n",
    "           learn_rate = 0.0001, prefixes=eng_prefixes, reverse=True, teach_force_ratio = 0.5,\n",
    "           attn_type = 'scalar', num_iters = 20000, every = 2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd89d516-0fd6-4931-9155-010e9372f8ef",
   "metadata": {},
   "source": [
    "## seq2seq с механизмом внимания MLP (GRU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ec347589-12f8-4e41-b962-76431ca9b71f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRU, mlp \n",
      "\n",
      "training\n",
      "===========================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d56095ff5bd44ad8b02f3cd75e39676a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 53s (- 7m 59s) (2000 10%) 3.2014 88.9710\n",
      "1m 46s (- 7m 6s) (4000 20%) 2.7373 40.7191\n",
      "2m 37s (- 6m 7s) (6000 30%) 2.5683 44.9015\n",
      "3m 29s (- 5m 14s) (8000 40%) 2.3912 32.8919\n",
      "4m 14s (- 4m 14s) (10000 50%) 2.2313 33.1566\n",
      "4m 57s (- 3m 18s) (12000 60%) 2.0905 25.8470\n",
      "5m 40s (- 2m 25s) (14000 70%) 2.0575 24.3882\n",
      "6m 29s (- 1m 37s) (16000 80%) 2.0522 38.1707\n",
      "7m 18s (- 0m 48s) (18000 90%) 1.9586 25.0213\n",
      "8m 9s (- 0m 0s) (20000 100%) 1.9084 25.8520\n",
      "\n",
      "evaluation\n",
      "\n",
      "> она в плохом настроении .\n",
      "= she s in a bad mood .\n",
      "< she is in a bad . <EOS>\n",
      "\n",
      "> я старше чем ты думаешь .\n",
      "= i m older than you think i am .\n",
      "< i m older than you than are you . <EOS>\n",
      "\n",
      "> ему день ото дня становится лучше .\n",
      "= he is getting better day by day .\n",
      "< he s better to his her . . <EOS>\n",
      "\n",
      "> я на три месяца младше вас .\n",
      "= i m three months younger than you .\n",
      "< i m three years younger than you . <EOS>\n",
      "\n",
      "> они наши друзья .\n",
      "= they re our friends .\n",
      "< they re friends friends . <EOS>\n",
      "\n",
      "> он сегодня берет выходнои .\n",
      "= he is taking a day off today .\n",
      "< he s looking at looking . <EOS>\n",
      "\n",
      "> я в этом почти уверен .\n",
      "= i m pretty certain of that .\n",
      "< i m sure of sure . <EOS>\n",
      "\n",
      "> я почти уверен .\n",
      "= i m pretty sure .\n",
      "< i m pretty sure . <EOS>\n",
      "\n",
      "> я почти слепои .\n",
      "= i m nearly blind .\n",
      "< i m almost a liar . <EOS>\n",
      "\n",
      "> я пытаюсь не разозлить тома .\n",
      "= i m trying not to make tom angry .\n",
      "< i m not tom to tom tom . <EOS>\n",
      "\n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "rnn_type = nn.GRU\n",
    "test_model(max_length = MAX_LENGTH,\n",
    "           learn_rate = 0.0001, prefixes=eng_prefixes, reverse=True, teach_force_ratio = 0.5,\n",
    "           attn_type = 'mlp', num_iters = 20000, every = 2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea18681-493f-44d9-a844-4195738ef066",
   "metadata": {},
   "source": [
    "## seq2seq с механизмом внимания MLP (LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d26004f0-f721-418a-ba05-fb932f3b56bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM, mlp \n",
      "\n",
      "training\n",
      "===========================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b8f18f8f61145b9901e6416a777355a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 51s (- 7m 42s) (2000 10%) 3.2005 87.0836\n",
      "1m 44s (- 6m 57s) (4000 20%) 2.8400 36.7685\n",
      "2m 34s (- 6m 1s) (6000 30%) 2.7034 33.0238\n",
      "3m 22s (- 5m 4s) (8000 40%) 2.5722 28.1855\n",
      "4m 12s (- 4m 12s) (10000 50%) 2.4540 33.0975\n",
      "5m 4s (- 3m 22s) (12000 60%) 2.4229 26.9914\n",
      "5m 56s (- 2m 32s) (14000 70%) 2.3337 26.9467\n",
      "6m 46s (- 1m 41s) (16000 80%) 2.2707 28.8761\n",
      "7m 34s (- 0m 50s) (18000 90%) 2.2328 26.9653\n",
      "8m 22s (- 0m 0s) (20000 100%) 2.1435 26.4678\n",
      "\n",
      "evaluation\n",
      "\n",
      "> я напугана .\n",
      "= i m frightened .\n",
      "< i m a . <EOS>\n",
      "\n",
      "> я уже так опаздываю .\n",
      "= i m already so late .\n",
      "< i m just a student . <EOS>\n",
      "\n",
      "> мы не живем вместе .\n",
      "= we re separated .\n",
      "< we re not longer anymore . <EOS>\n",
      "\n",
      "> он лучше нас всех .\n",
      "= he s better than us all .\n",
      "< he is the very of . <EOS>\n",
      "\n",
      "> вы следующии в очереди на повышение .\n",
      "= you are the next in line for promotion .\n",
      "< you re the best at the best . <EOS>\n",
      "\n",
      "> мы боимся смерти .\n",
      "= we re afraid of death .\n",
      "< we re going to . . <EOS>\n",
      "\n",
      "> я рад что ты здесь .\n",
      "= i m glad you re here .\n",
      "< i m glad you re here . <EOS>\n",
      "\n",
      "> он сеичас обедает .\n",
      "= he is having lunch now .\n",
      "< he is a now . <EOS>\n",
      "\n",
      "> она для меня не незнакомка .\n",
      "= she is no stranger to me .\n",
      "< she is not to go to . . <EOS>\n",
      "\n",
      "> они не одни .\n",
      "= they aren t alone .\n",
      "< they re not alone . <EOS>\n",
      "\n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "rnn_type = nn.LSTM\n",
    "test_model(max_length = MAX_LENGTH,\n",
    "           learn_rate = 0.0001, prefixes=eng_prefixes, reverse=True, teach_force_ratio = 0.5,\n",
    "           attn_type = 'mlp', num_iters = 20000, every = 2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccaa2d75-583e-4299-9dd8-9221ba95e4d7",
   "metadata": {},
   "source": [
    "# Итоги"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2b6cf8e4-330e-4407-97e7-d954614ca45a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RNN_Type</th>\n",
       "      <th>attn_types</th>\n",
       "      <th>loss</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>learning_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GRU</td>\n",
       "      <td>scalar</td>\n",
       "      <td>1.871842</td>\n",
       "      <td>26.617664</td>\n",
       "      <td>7m 53s (- 0m 0s)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GRU</td>\n",
       "      <td>mlp</td>\n",
       "      <td>1.908412</td>\n",
       "      <td>25.852019</td>\n",
       "      <td>8m 9s (- 0m 0s)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>mlp</td>\n",
       "      <td>2.143499</td>\n",
       "      <td>26.467788</td>\n",
       "      <td>8m 22s (- 0m 0s)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>scalar</td>\n",
       "      <td>2.150015</td>\n",
       "      <td>23.300525</td>\n",
       "      <td>9m 28s (- 0m 0s)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  RNN_Type attn_types      loss  perplexity     learning_time\n",
       "0      GRU     scalar  1.871842   26.617664  7m 53s (- 0m 0s)\n",
       "2      GRU        mlp  1.908412   25.852019   8m 9s (- 0m 0s)\n",
       "3     LSTM        mlp  2.143499   26.467788  8m 22s (- 0m 0s)\n",
       "1     LSTM     scalar  2.150015   23.300525  9m 28s (- 0m 0s)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by='loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f7cffb-14e0-4842-9f86-77711abd9e83",
   "metadata": {},
   "source": [
    "Лучшее качество модели по loss показала модель вида GRU с механизмом внимания scalar."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
