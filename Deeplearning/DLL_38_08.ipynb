{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8a828c6-b34b-468d-8775-fb3670118097",
   "metadata": {
    "id": "e0ebef84-7c99-40c8-b1db-44afe54ea513"
   },
   "source": [
    "# Домашнее задание по теме «Рекуррентные сети 3»"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d513b223-5b53-453f-8d7e-1075c087058c",
   "metadata": {},
   "source": [
    "1. Возьмите англо-русскую пару фраз (https://www.manythings.org/anki/)\n",
    "2. Обучите на них aeq2aeq по аналогии с заня4тием. Оцените полученное качество\n",
    "3. Попробуйте добавить +1 рекуррентный слой в encoder и decoder\n",
    "4. Попробуйте заменить GRU ячейки на ltsm-чейки6. Оцените качество во всех случаях\n",
    "5. Добавьте в лекционный ноутбук, в функцию train, обучение батчами"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721a8242-b3e8-4117-8bca-5fc7391f7bbc",
   "metadata": {
    "id": "ef2d935c-e4c6-46b9-bff0-8771b9d5ec95"
   },
   "source": [
    "# Загрузка библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "edb7eed8-5501-4f78-91ba-95f212e6b318",
   "metadata": {
    "id": "5687a1ec-c8d8-4cde-b87c-866621ec70d5"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6a9a7ca-8026-46a4-907b-9be6a8d86cc4",
   "metadata": {
    "id": "acfd831f-57e4-4d89-bdb4-8938dcbfcb58"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2003aa38-8cfb-4c60-9632-06f3ebd30fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "import os\n",
    "from io import open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f63a2cf4-291f-4abc-8c31-9a7374d90f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b7b35f6-011b-47b1-a48c-df27b537405e",
   "metadata": {
    "id": "93150af3-d550-46af-96a4-709507c17d8b"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "214b4abb-5f5f-4084-bdbf-70a0be836b1d",
   "metadata": {
    "id": "c41f774c-13f5-495c-b49a-0830e2e6202f"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "da01cfde-1b58-47cc-85cf-33666af21f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb683da5-4cbb-4e7e-b45b-f6321310d611",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d36bd0-a18c-4e96-9f6d-731d80322ed0",
   "metadata": {
    "id": "1438447f-21dc-48e1-909f-c64f95024466"
   },
   "source": [
    "# Параметры GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b12c1196-f9fb-412f-a716-222d7676fa7f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c248bc02-6322-4945-9528-b591ea42457a",
    "outputId": "55633407-4a96-43d7-917f-9610150f09d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA поддерживается системой?\n",
      "CUDA-версия: 11.8\n",
      "ID текущего CUDA устройства:0\n",
      "Имя текущего CUDA устройства:NVIDIA GeForce RTX 2060\n"
     ]
    }
   ],
   "source": [
    "print(f\"CUDA поддерживается системой?\")\n",
    "if torch.cuda.is_available() == True:\n",
    "    print(f\"CUDA-версия: {torch.version.cuda}\")\n",
    "    cuda_id = torch.cuda.current_device()\n",
    "    print(f\"ID текущего CUDA устройства:{torch.cuda.current_device()}\")\n",
    "    print(f\"Имя текущего CUDA устройства:{torch.cuda.get_device_name(cuda_id)}\")\n",
    "else:\n",
    "    print(f\"Нет\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05662382-87c6-4b7b-940d-179f201d765b",
   "metadata": {
    "id": "926f501b-2aa8-402d-b102-10a55b119dba"
   },
   "source": [
    "# Выбор процессора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4c29f5a8-c5f0-4d65-892f-3a1ec0e84289",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "1510b80a-79ca-4f09-a0d3-7e5ce1d99d67",
    "outputId": "c5b98f32-5890-4547-971e-744e35af4ad8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9f8521-9ca2-4f78-b867-e4a6a89ea472",
   "metadata": {},
   "source": [
    "# Импорт данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8b04f244-8fac-4720-b21e-c78983e5b3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = codecs.open( \"rus.txt\", \"r\", \"utf-8\" )\n",
    "data = file.read()\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8a992f01-5294-4bbe-8352-fe4d75445c2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ng.\tПоскольку сайтов, посвящённых какой-либо теме, как правило, несколько, я обычно просто нажимаю на кнопку \"назад\", если попадаю на страницу со всплывающей рекламой. Я просто перехожу на следующую страницу, найденную гуглом, и надеюсь найти что-то менее раздражающее.\tCC-BY 2.0 (France) Attribution: tatoeba.org #954270 (CK) & #6383010 (odexed)\n",
      "If someone who doesn't know your background says that you sound like a native speaker, it means they probably noticed something about your speaking that made them realize you weren't a native speaker. In other words, you don't really sound like a native speaker.\tЕсли кто-то незнакомый говорит, что вы говорите как носитель языка, это значит, что он, вероятно, заметил что-то в вашей речи, что дало ему понять, что вы не носитель. Другими словами, вы не говорите как носитель.\tCC-BY 2.0 (France) Attribution: tatoeba.org #953936 (CK) & #10644468 (notenoughsun)\n",
      "Doubtless there exists in this world precisely the right woman for any given man to marry and vice versa; but when you consider that a human being has the opportunity of being acquainted with only a few hundred people, and out of the few hundred that there are but a dozen or less whom he knows intimately, and out of the dozen, one or two friends at most, it will easily be seen, when we remember the number of millions who inhabit this world, that probably, since the earth was created, the right man has never yet met the right woman.\tНесомненно, для каждого мужчины в этом мире где-то есть подходящая женщина, которая может стать ему женой, обратное верно и для женщин. Но если учесть, что у человека может быть максимум несколько сотен знакомых, из которых лишь дюжина, а то и меньше, тех, кого он знает близко, а из этой дюжины у него один или от силы два друга, то можно легко увидеть, что с учётом миллионов живущих на Земле людей, ни один подходящий мужчина, возможно, ещё не встретил подходящую женщину.\tCC-BY 2.0 (France) Attribution: tatoeba.org #7697649 (RM) & #7730831 (odexed)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(data[-2000:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e984d51-57e1-4957-ba59-974142f771e3",
   "metadata": {},
   "source": [
    "# Входные параметры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "60647603-d9eb-4e6f-9d7d-c7bb8650c627",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "random.seed(SEED)\n",
    "MAX_LENGTH = 10\n",
    "num_file = 1\n",
    "learn_rate = 0.0001\n",
    "teach_force_ratio = 0.5\n",
    "num_iters = 30000\n",
    "every = num_iters/10\n",
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "lang1 = 'rus'\n",
    "lang2 = 'eng'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "080f330c-7252-45b2-84c5-d0066fe92a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "if device=='cuda':\n",
    "  torch.cuda.manual_seed(SEED)\n",
    "  torch.backends.cudnn.deterministic = True\n",
    "else:\n",
    "  torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "83b4f804-ac16-47c4-bec8-4441275372c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_prefixes = (\n",
    "    \"i am \", \"i m \",\n",
    "    \"he is\", \"he s \",\n",
    "    \"she is\", \"she s\",\n",
    "    \"you are\", \"you re \",\n",
    "    \"we are\", \"we re \",\n",
    "    \"they are\", \"they re \"\n",
    ")\n",
    "rnn_types = [nn.RNN, nn.LSTM, nn.GRU]\n",
    "num_hidden_lay_list = [1,2]\n",
    "cols = ['RNN_Type', 'Hidden_layers', 'Loss']\n",
    "PATH = os.path.abspath(\"rus.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200114ac-2d90-45ad-a1ce-54643b0c5ca9",
   "metadata": {},
   "source": [
    "# Функции"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb6a2ee-a9cb-4dad-95d1-a0af61bb93b4",
   "metadata": {},
   "source": [
    "## Фасовка слов по словарям"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ac9c538b-e365-4170-bb53-7158d3d02921",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2  # Count SOS and EOS\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b57ae31-502c-43a0-8e14-c5ab81fd4911",
   "metadata": {},
   "source": [
    "## Кодировка в ASCII"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "459f6141-d2d4-43bc-a3af-5e92c8cfbeea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c1ade5-ecf8-489c-941d-d74e108f612a",
   "metadata": {},
   "source": [
    "## Нормализация строк"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a72e0755-44fb-4af5-ab38-cc445939c77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Zа-яА-ЯёЁ.!?]+\", r\" \", s)\n",
    "    # s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9263b390-503a-43a2-99fc-5d813ab9ab40",
   "metadata": {},
   "source": [
    "## Чтение файла"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1118b120-139b-4cab-b03d-99ac6eb0f9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readLangs(lang1, lang2, reverse=False):\n",
    "    print(\"Reading lines...\")\n",
    "\n",
    "    # Read the file and split into lines\n",
    "    lines = open('rus.txt', encoding='utf-8').\\\n",
    "        read().strip().split('\\n')\n",
    "\n",
    "    # Split every line into pairs and normalize\n",
    "    pairs = [[normalizeString(s) for s in l.split('\\t')][:2] for l in lines] #\n",
    "\n",
    "    # Reverse pairs, make Lang instances\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang(lang2)\n",
    "        output_lang = Lang(lang1)\n",
    "    else:\n",
    "        input_lang = Lang(lang1)\n",
    "        output_lang = Lang(lang2)\n",
    "\n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c426b77-0eb2-4391-87ec-dfa59384c24f",
   "metadata": {},
   "source": [
    "## Токенизация слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f887edf9-0e31-4fc6-ada6-27df6e8aa580",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterPair(p, prefixes):\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
    "        len(p[1].split(' ')) < MAX_LENGTH and \\\n",
    "        p[1].startswith(prefixes)\n",
    "\n",
    "def filterPairs(pairs, prefixes):\n",
    "    return [pair for pair in pairs if filterPair(pair, prefixes)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ada6081-1138-423a-bb6d-2abe686f8c02",
   "metadata": {},
   "source": [
    "## Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1f1f1ee3-8fa1-4957-afc1-12d4c5fbddb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareData(lang1, lang2, prefixes, reverse=False):\n",
    "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    pairs = filterPairs(pairs, prefixes)\n",
    "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07cab7b-3d21-4d1e-bd43-7f9ddc88efa2",
   "metadata": {},
   "source": [
    "## Кодировщик"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b294e292-79a8-4cb5-bcd7-d4c9ea5ede05",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, n_layers, rnn_type):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.rnn = rnn_type(hidden_size, hidden_size, n_layers)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        output, hidden = self.rnn(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self, n_layers):\n",
    "        return torch.zeros(n_layers, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae662b56-e4d5-4bf9-b73f-6222d1405cbf",
   "metadata": {},
   "source": [
    "## Декодировщик"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8b8d0c83-3dcf-4ae4-ab72-2c348b265804",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, n_layers, rnn_type):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.rnn       = rnn_type(hidden_size, hidden_size, n_layers)\n",
    "        self.out       = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax   = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output         = self.embedding(input).view(1, 1, -1)\n",
    "        output         = F.relu(output)\n",
    "        output, hidden = self.rnn(output, hidden)\n",
    "        output         = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self, n_layers):\n",
    "        return torch.zeros(n_layers, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ceb9768-6c4a-4d33-a2cb-5d5f9cfa5a72",
   "metadata": {},
   "source": [
    "## Формирование тензора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e3dcc574-b622-4a33-86f7-3886a45f1fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "def tensorsFromPair(pair, input_lang, output_lang):\n",
    "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
    "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
    "    return (input_tensor, target_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4e65a5-db61-4633-bdf0-4702241370f2",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "00ad3be1-7505-422c-b99d-375dd16240f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(input_tensor, target_tensor,\n",
    "          encoder, decoder, encoder_optimizer, decoder_optimizer,\n",
    "          criterion, max_length, rnn_type, n_layers, teacher_forcing_ratio):\n",
    "    if rnn_type.__name__ == 'LSTM':\n",
    "        encoder_hidden = (encoder.initHidden(n_layers), encoder.initHidden(n_layers))\n",
    "    else:\n",
    "        encoder_hidden = encoder.initHidden(n_layers)\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_tensor[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden)\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            decoder_input = target_tensor[di]  # Teacher forcing\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            if decoder_input.item() == EOS_token:\n",
    "                break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf94fbc-6cb7-45f2-819b-d51e3dc9e5e8",
   "metadata": {},
   "source": [
    "## Для расчёта длительности обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "171c858b-f450-435a-81ec-1fe260dc0b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4437b83e-0c33-4233-875f-fca738bc5806",
   "metadata": {},
   "source": [
    "## Итеративное обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "46206762-9fd6-492e-b641-87fba638f787",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainIters(pair_sentenses, encoder, decoder, learning_rate, n_iters,\n",
    "               max_length, rnn_type, num_layers, teacher_forcing_ratio, input_lan, output_lan,\n",
    "               print_every=5000, plot_every=500):\n",
    "    start = time.time()\n",
    "    print_loss_total_loc = 0\n",
    "    print_loss_avg = 0\n",
    "\n",
    "    encoder_optimizer = optim.Adam(encoder.parameters())\n",
    "    decoder_optimizer = optim.Adam(decoder.parameters())\n",
    "\n",
    "    training_pairs = [tensorsFromPair(random.choice(pair_sentenses),\n",
    "                                      input_lan, output_lan)\n",
    "                                      for i in range(n_iters)]\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for iter in tqdm(range(1, n_iters + 1)):\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "\n",
    "        loss = train(input_tensor, target_tensor, encoder, decoder,\n",
    "                     encoder_optimizer, decoder_optimizer, criterion,\n",
    "                     max_length, rnn_type, num_layers, teacher_forcing_ratio)\n",
    "        print_loss_total_loc += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total_loc / print_every\n",
    "            print_loss_total_loc = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "    return print_loss_avg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5cf1d36-9710-4bc5-9207-8376748aefdb",
   "metadata": {},
   "source": [
    "## Оценка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a49eac62-d146-48ab-8647-f249bd71199a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, max_length, num_layers,\n",
    "             rnn_type, inp_lang, out_lang):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(inp_lang, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "\n",
    "        if rnn_type.__name__ == 'LSTM':\n",
    "            encoder_hidden = (encoder.initHidden(num_layers), encoder.initHidden(num_layers))\n",
    "        else:\n",
    "            encoder_hidden = encoder.initHidden(num_layers)\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
    "                                                     encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        decoded_words = []\n",
    "\n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden)\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            if topi.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(out_lang.index2word[topi.item()])\n",
    "\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        return decoded_words\n",
    "\n",
    "\n",
    "def evaluateRandomly(pair_sen, encoder, decoder, max_length,\n",
    "                     _lauers, rnn_, in_lang, o_lang,  n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pair_sen)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words = evaluate(encoder, decoder, pair[0], MAX_LENGTH,\n",
    "                                 _lauers, rnn_, in_lang, o_lang)\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce947a06-d12c-4b74-95c3-b23b70183548",
   "metadata": {},
   "source": [
    "## Функция для тестирования параметров по п. 3 и 4 задания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6eb0a19d-8689-403e-aa11-daef8fe4c5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(max_length_sent, num_hidden_lay_list, hidden_size = 256,\n",
    "               learn_rate = 0.006, prefixes=eng_prefixes, reverse=True,\n",
    "               teach_force_ratio = 0.5,\n",
    "               num_iters = 50000, every = 1000, num_file = 998):\n",
    "    \n",
    "        encoder2 = EncoderRNN(input_lang.n_words, hidden_size, num_layers, rnn_type\n",
    "                               ).to(device)\n",
    "        decoder2 = DecoderRNN(hidden_size, output_lang.n_words, num_layers, rnn_type\n",
    "                               ).to(device)\n",
    "\n",
    "        print(f'{rnn_type.__name__}, {num_layers} layers\\n\\ntraining')\n",
    "        print('===========================')\n",
    "\n",
    "        loss_ = trainIters(pair_s, encoder2, decoder2, learn_rate, num_iters,\n",
    "                          max_length_sent, rnn_type, num_layers, teach_force_ratio,\n",
    "                          input_lang, output_lang, every)\n",
    "\n",
    "        print('\\nevaluation\\n')\n",
    "\n",
    "        evaluateRandomly(pair_s, encoder2, decoder2, max_length_sent,\n",
    "                         num_layers, rnn_type, input_lang, output_lang)\n",
    "        print('----------------------------------------------------------------------')\n",
    "        string = [rnn_type.__name__, num_layers, loss_]\n",
    "        df.loc[len(df)] = string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e378776-afe9-4050-ba84-f8a6b075c5e6",
   "metadata": {},
   "source": [
    "# Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9124d3c2-e88c-4525-8756-1221e00939fc",
   "metadata": {},
   "source": [
    "## Подготовительное"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "41d5b003-dc31-40fa-9041-719c6498926b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 496059 sentence pairs\n",
      "Trimmed to 28719 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "eng 10177\n",
      "rus 4303\n",
      "['я младше его на два года .', 'i m two years younger than he is .']\n"
     ]
    }
   ],
   "source": [
    "input_lang, output_lang, pair_s = prepareData(lang1, lang2, prefixes=eng_prefixes, reverse=True)\n",
    "print(random.choice(pair_s))\n",
    "df = pd.DataFrame(columns=cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31bed7d-b2b8-49b7-af24-e3a907422a9e",
   "metadata": {},
   "source": [
    "## Тестирование параметров из задания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bd375ccd-7a2e-43ff-9cf6-7a6574628dd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN, 1 layers\n",
      "\n",
      "training\n",
      "===========================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fcf31497d7e4392817dd338731a466d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1m 3s (- 9m 33s) (3000 10%) 3.4043\n",
      "2m 13s (- 8m 55s) (6000 20%) 3.2492\n",
      "3m 26s (- 8m 2s) (9000 30%) 3.2702\n",
      "4m 37s (- 6m 56s) (12000 40%) 3.2185\n",
      "5m 48s (- 5m 48s) (15000 50%) 3.1966\n",
      "7m 8s (- 4m 45s) (18000 60%) 3.1657\n",
      "8m 24s (- 3m 36s) (21000 70%) 3.2519\n",
      "9m 38s (- 2m 24s) (24000 80%) 3.2258\n",
      "10m 42s (- 1m 11s) (27000 90%) 3.1517\n",
      "11m 49s (- 0m 0s) (30000 100%) 3.1952\n",
      "\n",
      "evaluation\n",
      "\n",
      "> я не сержусь на тома .\n",
      "= i m not mad at tom .\n",
      "< i m not sure . <EOS>\n",
      "\n",
      "> я уверен что том сказал правду .\n",
      "= i m sure that tom told the truth .\n",
      "< i m not sure . <EOS>\n",
      "\n",
      "> она сказала что не очень счастлива .\n",
      "= she said that she wasn t very happy .\n",
      "< she is into a hat . <EOS>\n",
      "\n",
      "> ты сегодня вечером очень разговорчив .\n",
      "= you re very talkative tonight .\n",
      "< you re not only . <EOS>\n",
      "\n",
      "> вы все такая же .\n",
      "= you re still the same .\n",
      "< you re not only . <EOS>\n",
      "\n",
      "> вы прекрасно подходите для этои работы .\n",
      "= you re perfect for the job .\n",
      "< you re not only . <EOS>\n",
      "\n",
      "> я слишком хочу спать чтобы делать домашнюю работу .\n",
      "= i m too sleepy to do my homework .\n",
      "< i m not sure . <EOS>\n",
      "\n",
      "> вы хорошии мальчик .\n",
      "= you re a good boy .\n",
      "< you re not only . <EOS>\n",
      "\n",
      "> ты модныи .\n",
      "= you re fashionable .\n",
      "< you re not only . <EOS>\n",
      "\n",
      "> вы еще здесь .\n",
      "= you re still here .\n",
      "< you re not only . <EOS>\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "RNN, 2 layers\n",
      "\n",
      "training\n",
      "===========================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8678d40ea1e46f398b6e4942470c778",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1m 20s (- 12m 7s) (3000 10%) 3.3902\n",
      "2m 29s (- 9m 58s) (6000 20%) 3.2538\n",
      "3m 46s (- 8m 47s) (9000 30%) 3.1834\n",
      "4m 58s (- 7m 28s) (12000 40%) 3.1201\n",
      "6m 25s (- 6m 25s) (15000 50%) 3.1506\n",
      "7m 51s (- 5m 14s) (18000 60%) 3.1164\n",
      "9m 26s (- 4m 2s) (21000 70%) 3.0664\n",
      "11m 0s (- 2m 45s) (24000 80%) 3.1055\n",
      "12m 30s (- 1m 23s) (27000 90%) 3.1136\n",
      "14m 9s (- 0m 0s) (30000 100%) 3.0974\n",
      "\n",
      "evaluation\n",
      "\n",
      "> они не боятся тяжелои работы .\n",
      "= they re not afraid of hard work .\n",
      "< they re not to . . . <EOS>\n",
      "\n",
      "> я в исподнем .\n",
      "= i m in my underwear .\n",
      "< i m glad you re to help . <EOS>\n",
      "\n",
      "> извини я должен идти .\n",
      "= i m sorry i have to go .\n",
      "< i m sorry i was that . <EOS>\n",
      "\n",
      "> за мнои следят .\n",
      "= i m being watched .\n",
      "< you re not going to . . <EOS>\n",
      "\n",
      "> ты чудовище .\n",
      "= you re a monster .\n",
      "< you re very attentive . <EOS>\n",
      "\n",
      "> она бросила сердитыи взгляд на грубого торговца .\n",
      "= she scowled at the rude salesman .\n",
      "< she is an . . . . <EOS>\n",
      "\n",
      "> я впечатлен вашеи работои .\n",
      "= i m impressed with your work .\n",
      "< i m glad you re to help . <EOS>\n",
      "\n",
      "> они еще молодые .\n",
      "= they re still young .\n",
      "< we re not to . . . <EOS>\n",
      "\n",
      "> я завтра женюсь .\n",
      "= i m getting married tomorrow .\n",
      "< i m glad you re to help . <EOS>\n",
      "\n",
      "> мне запрещено использовать этот телефон .\n",
      "= i am forbidden to use this telephone .\n",
      "< i m not a <EOS>\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "LSTM, 1 layers\n",
      "\n",
      "training\n",
      "===========================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b924de02fc444d01ade5e1d0dc6401ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 57s (- 8m 40s) (3000 10%) 3.0584\n",
      "1m 47s (- 7m 8s) (6000 20%) 2.6832\n",
      "2m 36s (- 6m 4s) (9000 30%) 2.4513\n",
      "3m 25s (- 5m 8s) (12000 40%) 2.3281\n",
      "4m 15s (- 4m 15s) (15000 50%) 2.1948\n",
      "5m 4s (- 3m 23s) (18000 60%) 2.1287\n",
      "5m 53s (- 2m 31s) (21000 70%) 2.0126\n",
      "6m 42s (- 1m 40s) (24000 80%) 1.9741\n",
      "7m 30s (- 0m 50s) (27000 90%) 1.9049\n",
      "8m 19s (- 0m 0s) (30000 100%) 1.8522\n",
      "\n",
      "evaluation\n",
      "\n",
      "> я не продам тебе мою машину .\n",
      "= i m not selling you my car .\n",
      "< i m not going to tell you . . <EOS>\n",
      "\n",
      "> мы боимся .\n",
      "= we re afraid .\n",
      "< we re a . <EOS>\n",
      "\n",
      "> вы опытныи .\n",
      "= you re experienced .\n",
      "< you re perfectly . <EOS>\n",
      "\n",
      "> ты слишком молода чтобы ехать туда однои .\n",
      "= you re too young to go there alone .\n",
      "< you re too young to go alone . <EOS>\n",
      "\n",
      "> они ко мне очень добры .\n",
      "= they are very kind to me .\n",
      "< they are very kind to me . <EOS>\n",
      "\n",
      "> я придерживаюсь своего плана .\n",
      "= i m sticking with my plan .\n",
      "< i m going to buy a . <EOS>\n",
      "\n",
      "> вам понравится работать на меня .\n",
      "= you re going to like working for me .\n",
      "< you re going to have to like me . <EOS>\n",
      "\n",
      "> я устал слушать как вы хвастаетесь .\n",
      "= i m tired of listening to your bragging .\n",
      "< i m tired of your tired . <EOS>\n",
      "\n",
      "> я сеичас занят .\n",
      "= i m in the middle of something .\n",
      "< i m busy now . <EOS>\n",
      "\n",
      "> я собираюсь сделать несколько звонков .\n",
      "= i m going to make some calls .\n",
      "< i m going to buy to do . <EOS>\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "LSTM, 2 layers\n",
      "\n",
      "training\n",
      "===========================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52d5726a47ac48c5836ddb6634e2cc00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1m 7s (- 10m 3s) (3000 10%) 3.1206\n",
      "2m 10s (- 8m 42s) (6000 20%) 2.7569\n",
      "3m 14s (- 7m 33s) (9000 30%) 2.5595\n",
      "4m 18s (- 6m 27s) (12000 40%) 2.4280\n",
      "5m 22s (- 5m 22s) (15000 50%) 2.3282\n",
      "6m 26s (- 4m 17s) (18000 60%) 2.2626\n",
      "7m 29s (- 3m 12s) (21000 70%) 2.1437\n",
      "8m 33s (- 2m 8s) (24000 80%) 2.0417\n",
      "9m 41s (- 1m 4s) (27000 90%) 2.0277\n",
      "10m 45s (- 0m 0s) (30000 100%) 1.9778\n",
      "\n",
      "evaluation\n",
      "\n",
      "> я очень рад что это случилось .\n",
      "= i m very happy that it happened .\n",
      "< i m really glad i did . <EOS>\n",
      "\n",
      "> они все очень голодны .\n",
      "= they are all very hungry .\n",
      "< they re all very hungry . <EOS>\n",
      "\n",
      "> ты очень важен для меня .\n",
      "= you re very important to me .\n",
      "< you re very lot me me . <EOS>\n",
      "\n",
      "> это я написал этот рассказ .\n",
      "= i m the one who wrote this story .\n",
      "< i m the one who stole this eggs . <EOS>\n",
      "\n",
      "> мы к этому не готовы .\n",
      "= we re not ready for this .\n",
      "< we re not afraid of that . <EOS>\n",
      "\n",
      "> я так счастлив что ты вернулся .\n",
      "= i m so happy you re back .\n",
      "< i m so glad you re back . <EOS>\n",
      "\n",
      "> ты не уволена .\n",
      "= you re not fired .\n",
      "< you aren t alone . <EOS>\n",
      "\n",
      "> я сеичас очень занят .\n",
      "= i m very busy now .\n",
      "< i m very busy now . <EOS>\n",
      "\n",
      "> можешь идти домои .\n",
      "= you are free to go home .\n",
      "< i m going to the . . <EOS>\n",
      "\n",
      "> ты сегодня рано .\n",
      "= you re early today .\n",
      "< you re going to . <EOS>\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "GRU, 1 layers\n",
      "\n",
      "training\n",
      "===========================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c8b200f58f049259ecd272a3624d954",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 48s (- 7m 13s) (3000 10%) 3.0362\n",
      "1m 32s (- 6m 11s) (6000 20%) 2.6074\n",
      "2m 18s (- 5m 22s) (9000 30%) 2.3112\n",
      "3m 3s (- 4m 34s) (12000 40%) 2.1636\n",
      "3m 47s (- 3m 47s) (15000 50%) 2.0573\n",
      "4m 32s (- 3m 1s) (18000 60%) 1.9107\n",
      "5m 17s (- 2m 16s) (21000 70%) 1.8403\n",
      "6m 2s (- 1m 30s) (24000 80%) 1.7590\n",
      "6m 47s (- 0m 45s) (27000 90%) 1.7161\n",
      "7m 32s (- 0m 0s) (30000 100%) 1.6392\n",
      "\n",
      "evaluation\n",
      "\n",
      "> я уверен что том не трус .\n",
      "= i m sure tom isn t a coward .\n",
      "< i m sure tom tom t that . <EOS>\n",
      "\n",
      "> вы не дурак .\n",
      "= you aren t stupid .\n",
      "< you re not stupid . <EOS>\n",
      "\n",
      "> я слишком маленькии чтобы идти в школу .\n",
      "= i m too young to go to school .\n",
      "< i m too young to go school . <EOS>\n",
      "\n",
      "> еи нужна помощь .\n",
      "= she is in need of help .\n",
      "< we re running out of help . <EOS>\n",
      "\n",
      "> он идеальныи муж для меня .\n",
      "= he is an ideal husband for me .\n",
      "< he is more me me . <EOS>\n",
      "\n",
      "> я собираюсь одобрить твои план .\n",
      "= i m going to approve your plan .\n",
      "< i m going to plan your plan . <EOS>\n",
      "\n",
      "> мы устраиваем тому вечеринку на день рождения .\n",
      "= we re throwing tom a birthday party .\n",
      "< we re hoping tom s here . . <EOS>\n",
      "\n",
      "> она беспокоится о здоровье своеи матери .\n",
      "= she is concerned about her mother s health .\n",
      "< she is concerned about her health . <EOS>\n",
      "\n",
      "> я окружена врагами .\n",
      "= i m surrounded by enemies .\n",
      "< i m just stuck . <EOS>\n",
      "\n",
      "> мы далеко не поедем .\n",
      "= we re not going far .\n",
      "< we re not going to . . <EOS>\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "GRU, 2 layers\n",
      "\n",
      "training\n",
      "===========================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e6f83ac729b4e90bab69acbcfa0f9a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2m 36s (- 23m 26s) (3000 10%) 3.1042\n",
      "5m 43s (- 22m 52s) (6000 20%) 2.7018\n",
      "8m 32s (- 19m 55s) (9000 30%) 2.5099\n",
      "10m 55s (- 16m 22s) (12000 40%) 2.3096\n",
      "13m 28s (- 13m 28s) (15000 50%) 2.2131\n",
      "16m 15s (- 10m 50s) (18000 60%) 2.1372\n",
      "19m 4s (- 8m 10s) (21000 70%) 1.9537\n",
      "21m 42s (- 5m 25s) (24000 80%) 1.9771\n",
      "24m 31s (- 2m 43s) (27000 90%) 1.8822\n",
      "27m 15s (- 0m 0s) (30000 100%) 1.8572\n",
      "\n",
      "evaluation\n",
      "\n",
      "> я устал слушать твои жалобы .\n",
      "= i m tired of listening to your complaints .\n",
      "< i m tired of your complaints . <EOS>\n",
      "\n",
      "> я твоего разрешения не спрашиваю .\n",
      "= i m not asking your permission .\n",
      "< i m not strong . <EOS>\n",
      "\n",
      "> она расчесывается .\n",
      "= she is brushing her hair .\n",
      "< she s a . . <EOS>\n",
      "\n",
      "> нам не терпится начать .\n",
      "= we re looking forward to getting started .\n",
      "< we re not happy . <EOS>\n",
      "\n",
      "> мне платят достаточно .\n",
      "= i m paid enough .\n",
      "< i m going to need . <EOS>\n",
      "\n",
      "> он не берет трубку .\n",
      "= he isn t answering his phone .\n",
      "< he s not very good . <EOS>\n",
      "\n",
      "> я мою посуду .\n",
      "= i m doing the dishes .\n",
      "< i m a . . <EOS>\n",
      "\n",
      "> я приятно этим удивлена .\n",
      "= i m pleasantly surprised by that .\n",
      "< i m planning to be . . <EOS>\n",
      "\n",
      "> я деиствительно с нетерпением жду вашего шоу .\n",
      "= i m really looking forward to your show .\n",
      "< i m really your your your happy . <EOS>\n",
      "\n",
      "> я готов драться .\n",
      "= i m ready to fight .\n",
      "< i m ready to die . <EOS>\n",
      "\n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "num_file = 1\n",
    "for rnn_type, num_layers in product(rnn_types, num_hidden_lay_list):\n",
    "  test_model(max_length_sent = MAX_LENGTH, num_hidden_lay_list = num_hidden_lay_list,\n",
    "           learn_rate = learn_rate, prefixes=eng_prefixes, reverse=True, teach_force_ratio = teach_force_ratio,\n",
    "           num_iters = num_iters, every = every, num_file = num_file)\n",
    "  num_file += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccaa2d75-583e-4299-9dd8-9221ba95e4d7",
   "metadata": {},
   "source": [
    "# Итоги"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2b6cf8e4-330e-4407-97e7-d954614ca45a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RNN_Type</th>\n",
       "      <th>Hidden_layers</th>\n",
       "      <th>Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GRU</td>\n",
       "      <td>1</td>\n",
       "      <td>1.639242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>1</td>\n",
       "      <td>1.852176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GRU</td>\n",
       "      <td>2</td>\n",
       "      <td>1.857226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>2</td>\n",
       "      <td>1.977753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RNN</td>\n",
       "      <td>2</td>\n",
       "      <td>3.097398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RNN</td>\n",
       "      <td>1</td>\n",
       "      <td>3.195249</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  RNN_Type  Hidden_layers      Loss\n",
       "4      GRU              1  1.639242\n",
       "2     LSTM              1  1.852176\n",
       "5      GRU              2  1.857226\n",
       "3     LSTM              2  1.977753\n",
       "1      RNN              2  3.097398\n",
       "0      RNN              1  3.195249"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by='Loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f7cffb-14e0-4842-9f86-77711abd9e83",
   "metadata": {},
   "source": [
    "Лучшее качество модели по loss показала модель вида GRU с 1 рекуррентным слоём."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
